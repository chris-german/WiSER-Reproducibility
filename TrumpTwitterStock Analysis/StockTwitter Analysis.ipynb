{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes over the code needed to reproduce the results from Trump Twitter/S&P 500 Stock data analysis using WiSER, namely Table 5 of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & Availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "President Trump's tweets (excluding retweets) from November 8th, 2016 to August 14th, 2020 were downloaded from http://www.trumptwitterarchive.com/.\n",
    "\n",
    "Unemployment Rate was downloaded from the Federal Reserve Economic Data (FRED) database at https://fred.stlouisfed.org/series/UNRATE. \n",
    "\n",
    "S&P 500 stock info was downloaded below. For the list of stocks in the S&P 500 market index, we obtained them from Wikipedia using the following python code:\n",
    "\n",
    "\n",
    "```\n",
    ">>> import pandas as pd\n",
    ">>> table=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    ">>> df = table[0]\n",
    ">>> df.to_csv('S&P500-Info.csv')\n",
    ">>> df.to_csv(\"S&P500-Symbols.csv\", columns=['Symbol'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading S&P 500 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.5.0\n",
      "Commit 96786e22cc (2020-08-01 23:44 UTC)\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-pc-linux-gnu)\n",
      "  CPU: Intel(R) Core(TM) i9-9920X CPU @ 3.50GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dates, MarketData, DataFrames, CSV, TimeZones, Statistics\n",
    "ENV[\"COLUMNS\"]=800\n",
    "SP500stockinfo = DataFrame!(CSV.File(\"S&P500-Info.csv\"))[!, [2, 5, 6, 7]]\n",
    "\n",
    "# Some stocks have `stock.B` but for YahooFinance they are coded `stock-B`. Need to change to that.\n",
    "SP500stockinfo[!, 1] = join.(split.(SP500stockinfo[!, 1], \".\"), \"-\");\n",
    "SP500stocks = join.(split.(SP500stockinfo[!, 1], \".\"), \"-\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain daily data on each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DateTime(2016, 11, 6) #starting date \n",
    "df = DataFrame()\n",
    "df = allowmissing(df)\n",
    "tickertmp = 0 \n",
    "for ticker in SP500stocks\n",
    "    try\n",
    "        tickertmp = allowmissing!(DataFrame!(yahoo(ticker, YahooOpt(period1=d))))\n",
    "        tickertmp[!, :Stock] .= ticker\n",
    "        tickertmp[!, :Yesterday_Close] = circshift(tickertmp[!, :Close], 1)\n",
    "        tickertmp[1, :Yesterday_Close] = missing #this is incorrect since it brings last value to first\n",
    "        append!(df, tickertmp)\n",
    "    catch      # 3 have missing values \n",
    "        try\n",
    "            allowmissing!(df)\n",
    "            tickertmp = DataFrame!(yahoo(ticker, YahooOpt(period1=d)))\n",
    "            tickertmp[!, :Stock] .= ticker\n",
    "            tickertmp[!, :Yesterday_Close] = circshift(tickertmp[!, :Close], 1)\n",
    "            tickertmp[1, :Yesterday_Close] = missing #this is incorrect since it brings last value to first\n",
    "            append!(df, tickertmp)\n",
    "        catch\n",
    "            println(ticker)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add variable Returns \n",
    "df[!, :Return] = (df[!, :Close] .- df[!, :Yesterday_Close]) ./ df[!, :Yesterday_Close]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join data together \n",
    "df = leftjoin(df, SP500stockinfo, on = :Stock => :Symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain daily data macroeconomic indictaors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treasury Yield 10 Years (^TNX)\n",
    "treasuryyield10yr = DataFrame!(yahoo(\"^TNX\", YahooOpt(period1=d)))[!, [:timestamp, :Close]]\n",
    "\n",
    "#CBOE Volatility Index (^VIX)\n",
    "volindex = DataFrame!(yahoo(\"^VIX\", YahooOpt(period1=d)))[!, [:timestamp, :Close]]\n",
    "\n",
    "#US Dollar Index (DX-Y.NYB)\n",
    "dollarindex = DataFrame!(yahoo(\"DX-Y.NYB\", YahooOpt(period1=d)))[!, [:timestamp, :Close]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to stock market data as variables. Going to use close prices?\n",
    "DataFrames.rename!(treasuryyield10yr, :Close => :Treasury_10YR_Yield)\n",
    "DataFrames.rename!(volindex, :Close => :VIX_Vol_Index)\n",
    "DataFrames.rename!(dollarindex, :Close => :Dollar_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = leftjoin(df, treasuryyield10yr, on = :timestamp)\n",
    "df = leftjoin(df, volindex, on = :timestamp)\n",
    "df = leftjoin(df, dollarindex, on = :timestamp)\n",
    "CSV.write(\"SP500dailydata.csv\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "This section goes over data cleaning and merging of the Twitter and Finance data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Trump Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dates, DataFrames, CSV, TimeZones, Statistics\n",
    "ENV[\"COLUMNS\"]=500\n",
    "tweets = DataFrame!(CSV.File(\"trumptweets2016_11_08_2020_08_14.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Times are recorded in GMT, convert times to Eastern Time in order to determine which stock day they may have had an impact on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DateFormat(\"mm-dd-yyyy HH:MM:SS\");\n",
    "tweets[!, :created_at] = Dates.DateTime.(tweets[!, :created_at], df);\n",
    "zdt = ZonedDateTime.(tweets[!, :created_at], tz\"GMT\")\n",
    "estDateTimes = astimezone.(zdt, tz\"America/New_York\")\n",
    "tweets[!, :created_at] = Dates.DateTime.(estDateTimes, Local) #Here local means the time that it is set (EST)\n",
    "tweets[!, :date] = Dates.Date.(estDateTimes, Local)\n",
    "tweets[!, :time] = Dates.Time.(tweets[!, :created_at])\n",
    "first(tweets, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to prepare tweets to match days the tweets may have had an effect on the market.\n",
    "\n",
    "- Find days market was open -> Tweet before closing? Stay same : Move to next day\n",
    "- Rest of days:\n",
    "    - Bank day? Move to next day\n",
    "    - Then if day is Saturday/Sunday (including adjusted bank day) -> Move to Monday\n",
    "    - See if any still lie on a holiday and shift them.\n",
    "    \n",
    "Bank holiday dates verified and used from https://gist.github.com/shivaas/4758439."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankholidays = DataFrame!(CSV.File(\"bankholidays.csv\", header=false));\n",
    "bankdates = bankholidays[!, 2];\n",
    "bankday_inds = findall(map(x -> x in bankdates, tweets[!, :date]));\n",
    "saturday_inds = findall(map(x -> dayname(x) in [\"Saturday\"], tweets[!, :date]));\n",
    "sunday_inds = findall(map(x -> dayname(x) in [\"Sunday\"], tweets[!, :date]));\n",
    "marketopeninds = setdiff(collect(1:length(tweets[!, :date])), union(bankday_inds, saturday_inds, sunday_inds));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trading hours are 9:30 a.m. to 4 p.m.\n",
    "# tradestart = Dates.Time(9, 30)\n",
    "tradestop = Dates.Time(16, 0)\n",
    "move_inds = findall(map(x -> x > tradestop, tweets[marketopeninds, :time])); #move these to next day \n",
    "\n",
    "#If tweet is made after market closes, move it to the next day.\n",
    "tweets[marketopeninds, :date][move_inds] = tweets[marketopeninds, :date][move_inds] .+ Dates.Day(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is tweet a bank holiday? Add a day \n",
    "tweets[bankday_inds, :date] = tweets[bankday_inds, :date] .+ Dates.Day(1)\n",
    "\n",
    "# now recalculate saturday and sunday inds for bankdays that moved to saturday or sunday\n",
    "saturday_inds = findall(map(x -> dayname(x) in [\"Saturday\"], tweets[!, :date]));\n",
    "sunday_inds = findall(map(x -> dayname(x) in [\"Sunday\"], tweets[!, :date]));\n",
    "\n",
    "# Is tweet on a Saturday ? Add two days \n",
    "tweets[saturday_inds, :date] = tweets[saturday_inds, :date] .+ Dates.Day(2)\n",
    "# Is tweet on a Sunday ? Add one day \n",
    "tweets[sunday_inds, :date] = tweets[sunday_inds, :date] .+ Dates.Day(1)\n",
    "\n",
    "# Now some of these days may be on a Monday that's a bank holiday. Just re-calculate if they are on a bank holiday and shift them a day again. \n",
    "bankday_inds = findall(map(x -> x in bankdates, tweets[!, :date]));\n",
    "@show length(bankday_inds)\n",
    "tweets[bankday_inds, :date] = tweets[bankday_inds, :date] .+ Dates.Day(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate tweets on the same day together \n",
    "dailytweets = combine(groupby(tweets, :date), :text => (x -> join(x, \" \")) => :day_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reports 0, 0 indicating all tweets have been shifted \n",
    "(findall(map(x -> dayname(x) in bankdates, tweets[!, :date])), findall(map(x -> dayname(x) in [\"Sunday\", \"Sunday\"], tweets[!, :date]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"dailytrumptweets_shifteddays.csv\", dailytweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging S&P 500, Unemployment, and Trump Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load S&P data\n",
    "df = DataFrame!(CSV.File(\"SP500dailydata.csv\"))\n",
    "# downloaded from https://fred.stlouisfed.org/series/UNRATE. \n",
    "unrate = DataFrame!(CSV.File(\"UNRATE.csv\"))\n",
    "\n",
    "# Tweets by day, linking tweets to days they could have had an effect on the market \n",
    "daily_alltrumptweets = DataFrame!(CSV.File(\"dailytrumptweets_shifteddays.csv\"))\n",
    "last(daily_alltrumptweets, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all tweets to lowercase\n",
    "daily_alltrumptweets[!, :day_tweets] = lowercase.(daily_alltrumptweets[!, :day_tweets]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of words to obtain daily counts for in Trump's tweets\n",
    "top20_wordslist = lowercase.([\"China\", \"Billion\", \"Products\", \"Democrats\", \"Great\", \"Dollars\", \"Tariffs\", \"Country\", \"Mueller\", \"Border\", \"President\",\n",
    "\"Congressman\", \"People\", \"Korea\", \"Party\", \"Years\", \"Farmers\", \"Going\", \"Trade\", \"Never\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count times a word appears in a String.\n",
    "function numoccursin(word, text)\n",
    "    splittext = split(text, \" \")\n",
    "    return length(findall(occursin.(word, splittext)))\n",
    "end\n",
    "\n",
    "#obtain the counts \n",
    "for word in top20_wordslist\n",
    "    # count number of times words appeared in tweet that day \n",
    "    daily_alltrumptweets[!, Symbol(word * \"_count\")] = map(x -> numoccursin(word, x), daily_alltrumptweets[!, :day_tweets])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For size, don't need to keep text data\n",
    "deletecols!(daily_alltrumptweets, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge S&P 500 data with Trump twitter data\n",
    "df = leftjoin(df, daily_alltrumptweets, on =  :timestamp => :date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get year/month to merge the umemployment rate (monthly) data to the data set. \n",
    "df.yearmonth = Date.(Dates.Month.(df.timestamp), Dates.Year.(df.timestamp));\n",
    "\n",
    "# merge unemployment data to dataset\n",
    "df = leftjoin(df, unrate, on = :yearmonth => :DATE)\n",
    "\n",
    "#final dataset\n",
    "CSV.write(\"daily_trumptweets_shiftedtweetdays_snp500stocks.csv\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The following is the analysis conducted for Table 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages & read in data\n",
    "using DataFrames, CSV, WiSER, Statistics, KNITRO, StatsBase, Dates\n",
    "ENV[\"COLUMNS\"]=1200\n",
    "\n",
    "# tweets were shifted to match market days they could have an impact on\n",
    "shifteddf = DataFrame!(CSV.File(\"daily_trumptweets_shiftedtweetdays_snp500stocks.csv\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change variable names and set Financials as default sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames.rename!(shifteddf, Symbol(\"GICS Sector\") => :Sector)\n",
    "DataFrames.rename!(shifteddf, Symbol(\"GICS Sub Industry\") => :Sub_Industry);\n",
    "\n",
    "shifteddf[!, :Sector] = levels!(CategoricalArray(shifteddf[!, :Sector]),\n",
    "    [\"Financials\", \"Industrials\", \"Communication Services\", \"Information Technology\", \"Health Care\", \"Consumer Discretionary\", \"Materials\", \"Consumer Staples\",\n",
    "        \"Energy\", \"Real Estate\", \"Utilities\"]);\n",
    "\n",
    "# create Return_Percentage variable (Return * 100)\n",
    "shifteddf.Return_Percentage = shifteddf.Return .* 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Covid Period Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 24 2020, https://www.bbc.com/news/business-51612520 Global stock markets plunge on coronavirus fears\n",
    "# In the US, the Dow Jones and S&P 500 posted their sharpest daily declines since 2018, with the Dow falling 3.5% or more than 1,000 points.\n",
    "\n",
    "#https://www.axios.com/coronavirus-stock-market-timeline-sp-500-404ba78a-0466-4036-9506-1f981bc2689f.html \n",
    "postcovidstart = Date(Dates.Day(24), Dates.Month(2),Dates.Year(2020))\n",
    "\n",
    "shifteddf.postcovid = shifteddf.timestamp .>= postcovidstart\n",
    "# beforemarketclosedf.postcovid = beforemarketclosedf.timestamp .>= postcovidstart;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a lag of yesterday's returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lag(x)\n",
    "    last_x = circshift(x, 1)\n",
    "    last_x[1] = missing # no yesterday's return of first return \n",
    "    return last_x\n",
    "end\n",
    "\n",
    "shifteddf = transform(groupby(shifteddf, :Stock), :Return => lag => :Return_yday)\n",
    "shifteddf = transform(groupby(shifteddf, :Stock), :Return_Percentage => lag => :Return_Percentage_yday);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = KNITRO.KnitroSolver(outlev=0, ftol=2)\n",
    "sp500returns_shifted_covid = WSVarLmmModel(@formula(Return_Percentage ~ 1 + Sector * postcovid + Treasury_10YR_Yield + VIX_Vol_Index + \n",
    "        Dollar_Index + UNRATE + UNRATE & postcovid + china_count + billion_count + products_count + democrats_count + great_count + \n",
    "        dollars_count + tariffs_count + country_count + mueller_count +\n",
    "        border_count + president_count + congressman_count + people_count + \n",
    "        korea_count + party_count + years_count + farmers_count + going_count + trade_count + never_count + Return_Percentage_yday),\n",
    "    @formula(Return_Percentage ~ 1 + Return_Percentage_yday), \n",
    "    @formula(Return_Percentage ~ 1 + Sector * postcovid + Treasury_10YR_Yield + VIX_Vol_Index + \n",
    "        Dollar_Index + UNRATE + UNRATE & postcovid + china_count + billion_count + products_count + democrats_count + great_count + \n",
    "        dollars_count + tariffs_count + country_count + mueller_count +\n",
    "        border_count + president_count + congressman_count + people_count + \n",
    "        korea_count + party_count + years_count + farmers_count + going_count + trade_count + never_count), \n",
    "    :Stock, shifteddf);\n",
    "@time WiSER.fit!(sp500returns_shifted_covid, solver,\n",
    "    parallel = false, runs = 12, init = init_ls!(sp500returns_shifted_covid, gniters = 0)) #use knitro & LS with NO Gauss Newton iterations to initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change variable names for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_names = [\"Intercept\", \"Sector: Industrials\", \"Sector: Communication Services\", \n",
    "    \"Sector: Information Technology\", \"Sector: Health Care\", \"Sector: Consumer Discretionary\", \n",
    "    \"Sector: Materials\", \"Sector: Consumer Staples\", \"Sector: Energy\", \"Sector: Real Estate\", \n",
    "    \"Sector: Utilities\", \"Covid Period\", \"US Treasury 10yr Yield\", \"VIX Volatility Index\", \"US Dollar Index\", \n",
    "    \"US Unemployment Rate\", \"Tweet Count: China \", \"Tweets Count: Billion\", \"Tweets Count: Products\",\n",
    "    \"Tweets Count: Democrats\", \"Tweets Count: Great\", \"Tweets Count: Dollars\", \"Tweets Count: Tariffs\", \n",
    "    \"Tweets Count: Country\", \"Tweets Count: Mueller\", \"Tweets Count: Border\", \"Tweets Count: President\", \n",
    "    \"Tweets Count: Congressman\", \"Tweets Count: People\", \"Tweets Count: Korea\", \"Tweets Count: Party\", \n",
    "    \"Tweets Count: Years\", \"Tweets Count: Farmers\", \"Tweets Count: Going\", \n",
    "    \"Tweets Count: Trade\", \"Tweets Count: Never\", \"Previous Return Percentage\", \"Sector: Industrials \\\\& Covid Period\", \n",
    "    \"Sector: Communication Services \\\\& Covid Period\", \n",
    "    \"Sector: Information Technology \\\\& Covid Period\", \"Sector: Health Care \\\\& Covid Period\", \n",
    "    \"Sector: Consumer Discretionary \\\\& Covid Period\", \n",
    "    \"Sector: Materials \\\\& Covid Period\", \"Sector: Consumer Staples \\\\& Covid Period\", \n",
    "    \"Sector: Energy \\\\& Covid Period\", \"Sector: Real Estate \\\\& Covid Period\", \n",
    "    \"Sector: Utilities \\\\& Covid Period\", \"US Unemployment Rate \\\\& Covid Period\"]\n",
    "\n",
    "wsvar_names = [\"Intercept\", \"Sector: Industrials\", \"Sector: Communication Services\", \n",
    "    \"Sector: Information Technology\", \"Sector: Health Care\", \"Sector: Consumer Discretionary\", \n",
    "    \"Sector: Materials\", \"Sector: Consumer Staples\", \"Sector: Energy\", \"Sector: Real Estate\", \n",
    "    \"Sector: Utilities\", \"Covid Period\", \"US Treasury 10yr Yield\", \"VIX Volatility Index\", \"US Dollar Index\", \n",
    "    \"US Unemployment Rate\", \"Tweet Count: China \", \"Tweets Count: Billion\", \"Tweets Count: Products\",\n",
    "    \"Tweets Count: Democrats\", \"Tweets Count: Great\", \"Tweets Count: Dollars\", \"Tweets Count: Tariffs\", \n",
    "    \"Tweets Count: Country\", \"Tweets Count: Mueller\", \"Tweets Count: Border\", \"Tweets Count: President\", \n",
    "    \"Tweets Count: Congressman\", \"Tweets Count: People\", \"Tweets Count: Korea\", \"Tweets Count: Party\", \n",
    "    \"Tweets Count: Years\", \"Tweets Count: Farmers\", \"Tweets Count: Going\", \n",
    "    \"Tweets Count: Trade\", \"Tweets Count: Never\", \"Sector: Industrials \\\\& Covid Period\", \n",
    "    \"Sector: Communication Services \\\\& Covid Period\", \n",
    "    \"Sector: Information Technology \\\\& Covid Period\", \"Sector: Health Care \\\\& Covid Period\", \n",
    "    \"Sector: Consumer Discretionary \\\\& Covid Period\", \n",
    "    \"Sector: Materials \\\\& Covid Period\", \"Sector: Consumer Staples \\\\& Covid Period\", \n",
    "    \"Sector: Energy \\\\& Covid Period\", \"Sector: Real Estate \\\\& Covid Period\", \n",
    "    \"Sector: Utilities \\\\& Covid Period\", \"US Unemployment Rate \\\\& Covid Period\"]\n",
    "\n",
    "\n",
    "sp500returns_shifted_covid.meannames .= mean_names\n",
    "sp500returns_shifted_covid.wsvarnames .= wsvar_names\n",
    "\n",
    "# results presented in Table 5.\n",
    "sp500returns_shifted_covid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
